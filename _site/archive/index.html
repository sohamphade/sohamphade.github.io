<!DOCTYPE html>
<html lang="en" data-theme="dark-poole">
  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>
    
      Archive &middot; Soham Phade
    
  </title>

  <link rel="stylesheet" type="text/css" href="http://sohamphade.github.io/_site/styles.css">
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://sohamphade.github.io/_site/assets/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="http://sohamphade.github.io/_site/assets/favicon.ico">
  <link rel="alternate" type="application/atom+xml" title="Soham Phade" href="http://sohamphade.github.io/_site/atom.xml">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

  <!-- Begin Jekyll SEO tag v2.6.1 -->
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Archive" />
<meta name="author" content="Soham Phade" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="http://sohamphade.github.io/_site/archive/" />
<meta property="og:url" content="http://sohamphade.github.io/_site/archive/" />
<meta property="og:site_name" content="Soham Phade" />
<script type="application/ld+json">
{"url":"http://sohamphade.github.io/_site/archive/","author":{"@type":"Person","name":"Soham Phade"},"headline":"Archive","@type":"WebPage","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

</head>


  <body>
    <div class="container content">
      <header class="masthead">
        <h3 class="masthead-title">
          
            <a href="http://sohamphade.github.io/_site/index.html">Soham Phade</a>
            
          <nav class="nav">
            
            <small><a class="" href="http://sohamphade.github.io/_site/index.html">About </a></small>
            
            <small><a class="" href="http://sohamphade.github.io/_site/research/index.html">Research </a></small>
            
            <small><a class="current" href="http://sohamphade.github.io/_site/archive/index.html">Blog </a></small>
            
            <small><a href="http://sohamphade.github.io/_site/assets/CV.pdf">CV </a></small>
          </nav>
        </h3>
      </header>

      <main>
        <!-- 


  <h2>January 2021</h2>
  <ul>
    
      <li><a href="http://sohamphade.github.io/_site/gt_ecommerce//index.html">What does Game Theory have to say about E-Commerce?</a></li>
    
  </ul>

  <h2>November 2020</h2>
  <ul>
    
      <li><a href="http://sohamphade.github.io/_site/cptgames//index.html">Game Theory and Market Design when Agents have Cumulative Prospect Theory Preferences</a></li>
    
      <li><a href="http://sohamphade.github.io/_site/basd//index.html">Behavior-Aware System Design</a></li>
    
  </ul>
 --->

<!-- 
<li><a href="http://sohamphade.github.io/_site/gt_ecommerce//index.html">What does Game Theory have to say about E-Commerce?</a></li>

<li><a href="http://sohamphade.github.io/_site/cptgames//index.html">Game Theory and Market Design when Agents have Cumulative Prospect Theory Preferences</a></li>

<li><a href="http://sohamphade.github.io/_site/basd//index.html">Behavior-Aware System Design</a></li>
 --->

<hr style="height:2px;border-width:0;color:gray;background-color:gray" />

<div class="bcolumn">
  <a href="http://sohamphade.github.io/_site/gt_ecommerce/index.html" style="text-decoration: none;">
  <article class="post">
  	<h2 class="post-title">What does Game Theory have to say about E-Commerce?</h2>
    <time datetime="2021-01-17T00:00:00-08:00" class="post-date">17 Jan 2021</time>
    <h4> A theoretical approach with three key stages - personalized recommendations, surge pricing, and data processing. </h4>
    <!--
    E-commerce applications have enabled economic aspects 
– such as production, distribution, and consumption of goods and services – 
to permeate our social fabric to an extent never seen before. 
The task ahead is to bring some of the old principles from social sciences like economics and psychology, with suitable modifications, 
into the modern digital world of algorithms and technology. 
In this post, I will expand on a theoretical approach
that I believe can provide new insights in this regard.

E-commerce has not only brought the physical world to our doorstep and into our palms, but it has also vastly expanded the arena for social interactions. 
Think of any platform like Amazon, Facebook, or Youtube. 
You can do almost anything with just a few clicks. You can interact with several other individuals, exchange ideas, 
perform transactions, run your businesses, or cultivate your passions. The possibilities are unlimited.

The smooth functioning of these systems is essential. 
On the systems side, we have tasks such as inventory management and supply chain logistics. 
It requires creating and maintaining the website, platform services, and other operations that would scale as per the need. 
We have extensive infrastructures built for them that have been rapidly evolving over the past few decades. 
On the other hand, we have a massive industry catered towards marketing and maintaining customer relations, 
with a growing trend for using algorithms and social media networks to target customers.

Equally important is the interaction between the system and its users. 
A basic example of such is the search engine. 
Imagine how hard it would be to find some website over the Internet, view a particular video on Youtube, or purchase an item over Amazon without a well-functioning search engine.

The first stage of interaction involves assisting the users to reach their most favorable option(s). 
Let’s say each user has a type that describes her intent (or maybe, just the fact that there are no intentions and she is open to suggestions). 
(I have purposely used the word “type” here because, later, 
I will put this in the technical framework of mechanism design, where it is common to assume that the players have types.) 
This first stage varies from being passive to aggressive. 
The passiveness comes from it seeking to learn the user’s preferences. 
And the aggressiveness comes from it attempting to alter the user’s intentions. 
A simple phone directory is an example of a passive search assistant. 
On the other hand, the news feeds on social media or the video recommendations on YouTube are strong influencers and are much more aggressive. 
Usual gadgets like recommendation systems, search suggestions, and advertisements often lie somewhere on this scale based on their design.

No doubt this is a powerful mode of interaction, and we must ask ourselves the following question: 
What are its objectives and what are its effects on the system, and, in particular, on the users of this system? 
It affects the way we think, the things we believe, and the way we behave. 
There is a growing awareness of this effect, 
and many amongst us would agree that we can no more ignore these effects. 
It is time to bring in the lessons learned over centuries through real-world interactions into the world of the web. 
It is a loaded task with several people working on it. 
Studying the purpose and the effect of these systems systematically will help shed some light in this direction. 
It will help improve the design of these systems.

The next stage is to decide who gets what. 
Resources are limited! 
(On a philosophical note, I believe it is one of the defining facts of our lives, 
the underlying reason for why we do most of the things we do the way we do it.) 
Coming back to our e-commerce platforms, consider something like Amazon. 
The number of items available for sale is limited. 
The resources available for shipping are scarce. 
Network bandwidth is bounded. 
Cloud storage and computing resources are limited. 
With these limitations, the system has to allocate resources according to the different preferences of its customers.

To achieve this task, we need to design a protocol for the people to signal how badly they intend to receive the resources. 
When kids fight over an item, the one who makes the most noise generally gets it. 
You make them put in efforts to gauge how badly they need the resources. 
Similarly, for elders, a commonly employed method is to make them pay — the more they are willing to pay, the more they want it. 
Another approach is to make the users put in efforts like waiting in a queue or tolerate being hammered by advertisements.

On the topic of advertisements, it is interesting to look at the ad-supported platforms like Youtube, Facebook, or Google in an inverted form. 
Here, the users are the ones who have limited attention spans, and the software is trying to feed them with a maximum number of adverts with the most targeted influence. 
Notice that the advertisers are the customers in this case, who are ready to pay for the limited valuable resource, namely, the users’ attention.

The best way to execute this stage is to provide the customers with their most desired options with varying charges based on the market demand. 
A simple example is that of Uber giving different service options to its customers at varying prices. 
Amazon provides multiple delivery options with varying charges. Just as recommendations were a logical answer for the vastness of search, pricing/effort extraction is a natural way to allocate resources amongst competing entities.

These pricing strategies affect the revenue of the company. 
They also determine the customer-company relations. 
A better understanding of the customers’ behavioral responses will go a long way in designing these systems. 
Several answers to this study will come from economics and game theory. 
(See Behavior-Aware System Design post for further discussion on this.)

The final stage is that of incorporating feedback. 
It includes operations like keeping track of user actions, choices, responses, and ratings; collecting and processing this data. 
The digital revolution and the emergence of companies with billions of users have made it possible to collect this data at relatively low costs. If used correctly, we can certainly benefit from it. 
It will help improve the effectiveness of the previous two stages.


  


All this might sound similar to several articles over the Internet trumpeting cool ideas in the form of mantras or principles. 
But the question that I am interested in is whether we can translate these ideas into a proper working model that can be analyzed mathematically.

Why should we do this? Although intuition and ideas are great, they are often just the first step. 
Consider the example of constructing a bridge. 
Maybe we can build a small one across a creek using intuition and ideas. 
But to create something magnificent like the Golden Gate Bridge, we need some serious engineering tools based on concrete mathematical theories. 
We need to account for several factors such as the strength requirements, the weather conditions, 
and the soil composition to determine the materials to be used, the building’s architecture, and the construction method.

The same holds for any engineering task. 
As the scale grows, the task becomes more and more complicated, and it becomes imperative to have a well-established set of assumptions and objectives to execute these tasks. 
For example, once we know what we expect from the bridge, like the amount of traffic that is supposed to pass every day, the kind of maintenance that is feasible, and the expected life span of the bridge, then, 
using mathematical models that are based on scientific laws, we can build a working model to proceed.

Theory alone certainly cannot answer everything. Here is an excerpt from Roth and Peranson (1999) that wonderfully explains this:


  Consider the design of suspension bridges. The Newtonian physics they embody is beautiful both in mathematics and in steel, and college students can be taught to derive the curves that describe the shape of the supporting cables. But no bridge could be built based only on this elegant theoretical treatment, in which the only force is gravity, and all beams are perfectly rigid. Real bridges are built of steel and rest on rock and soil and water, and so bridge design also concerns metal fatigue, soil mechanics, and the forces of waves and wind. Many design questions concerning these real-world complications cannot be answered analytically but, instead, must be explored using physical or computational models. Often these involve estimating magnitudes of phenomena missing from the simple Newtonian model, some of which are small enough to be of little consequence, while others will cause the bridge to fall down if not adequately addressed. Just as no suspension bridges could be built without an understanding of the underlying physics, neither could any be built without understanding many additional features, also physical in nature, but more varied and complex than addressed by the simple model. These additional features, and how they are related to and interact with that part of the physics captured by the simple model, are the concern of the scientific literature of engineering. Some of this is less elegant than the Newtonian model, but it is what makes bridges stand. Just as important, it allows bridges designed on the same basic Newtonian model to be built longer, stronger, and lighter over time, as the complexities and how to deal with them become better understood.


For our task of building reliable e-commerce applications, 
we have sophisticated models to study some of the components of this system. 
Thanks to the engineering sciences, we know a lot about the software and the hardware side of the problem. 
However, we are still missing a vital component, namely the human aspect. 
In all these applications, human interaction with the platform is a prime factor. It not only affects the future of that e-commerce application but also has a significant impact on society. Any theory-based approach towards designing these systems must be qualified to account for it.


    
        "Game theory can be defined as the study of mathematical models of conflict and cooperation between intelligent rational decision-makers." 
    
    —Roger B. Myerson, Game Theory - Analysis of Conflict


This is where game theory and economics come into the picture.
Mechanism design, which is often called the engineering side of game theory, is just what we need. 
To give a very crude description of the basic premise of mechanism design, say you have some participants. 
Think of them as the users for whom we are designing the system. Each of these participants is assumed to have a specific type that describes their needs, behavior, and intentions. 
The system operator has a bunch of options that it can execute given the resource constraints. 
However, it does not know the individual types of participants. It can set up a game scenario, where the participants interact strategically with each other resulting in an equilibrium outcome depending on the appropriate equilibrium notion. 
The mechanism designer’s objective is to produce the equilibrium outcome that satisfies some desired characteristics conditioned on the types of the participants, even without directly observing the types of the participants.

The most commonly known example of mechanism design is an auction. Imagine an auction house. 
Different participants have different valuations for the art piece. 
This valuation information is a part of their types. You wish to assign the item to the person who values it the most and subsequently extract the maximum possible price. 
The mechanism design that achieves such a task is the bidding protocol. 
Making the participates bid strategically to win the item at the lowest possible price not only makes them reveal information about their valuations but also allows the auctioneer to sell the item to the bidder who values it the most and correspondingly get a better price for the item.

Different bidding protocols have different features. 
The mechanism design framework allows us to study these features systematically. 
For example, if we have certain beliefs about the valuations of the participants, then Myerson’s optimal auction provides a way to design a mechanism that maximizes the revenue. 
If you want each participant to report her valuation truthfully and assign the item to the highest bidder, then one must use the Vickrey-Clarke-Groves auction, which takes the form of a second-price sealed-bid auction in this case. 
Dutch auction and English auction are other examples. 
The 2020 Economics Nobel Memorial Prize was awarded to Robert B. Wilson and Paul Milgrom for their work on auction theory. It played a crucial role in the design of F.C.C. spectrum auctions.

Let us look at another example. 
Imagine a car riding service like Uber. 
Different riders have different requirements depending on their preferences and purpose of travel. 
For someone who is going to the airport to catch a flight, she will assign a lot of importance to her arrival time. 
Someone else who is not in a hurry might want the cheapest option and be ready to share her ride. 
Let us club all these preferences into the different types of users. 
Now the platform’s task is to assign rides to different users along with the routes to satisfy certain goals. 
These goals could be something like getting each individual the best service possible depending on her preferences, raising the maximum revenue possible, allocating resources in an environment-friendly manner allowing for maximum sharing as possible, or some combination of these different goals.

Intuitively, we know that we should show multiple options to the riders with corresponding prices and let them select what they like. 
This constitutes the first two stages. 
In the first stage, you present the best options available based on the information provided by each customer, like destination, estimated time of arrival, number of passengers, etc. 
Then, in the second stage, you identify how badly each individual wants their preferences to be satisfied by asking them to pay for the services accordingly.
Having realized this, is there some way we can construct these options systematically and then based on the users’ selections assign appropriate resources? 
Can theory help us answer this question and subsequently design algorithms with some quantitative guarantees?

To some extent, the role of any mechanism is to provide a communication protocol through which the users’ choices and actions can be coordinated. 
Now, in general, one could imagine a countless number of different communication schemes. 
So, where does one start to search for the so-called optimal mechanism? Fortunately, the theory of mechanism design offers some reassurance.

Revelation principle, one of the most fascinating results from mechanism design, roughly says that if you can design a communication protocol that has certain features under strategic play, 
then there exists an equivalent direct mechanism, where you ask each user to simply state its type and allocate resources so that the resulting protocol under strategic play has the same features. 
Think of the second-price sealed-bid auction. 
Each person submits a sealed bid for the auction item, and the person with the highest bid wins the item and pays the amount equal to the second-highest bid. 
The nice feature about this protocol is that it is in the best interest of each person to report her true valuation. 
All direct mechanisms have this property. 
The revelation principle says that you can restrict your attention to such direct mechanisms without loss of generality.

To put this in the context of our three-stage structure, it seems that a direct mechanism only consists of the second stage, 
where each user is presented with a list of options, one corresponding to each of her types, with corresponding outcomes and prices, and the user chooses one amongst them that best suits her. 
This is the one that corresponds to her type. So the revelation principle seems to suggest that it is enough to construct platforms with just the second stage.
But there are several problems with this reasoning as you might have guessed.

For instance, the number of possible types could be very large, and it is not feasible to present each user with an option corresponding to each type. 
In the case of Amazon, this would mean presenting each customer with all the items available to shop on the platform. 
This suggests why we need the first stage. 
But this is not the only reason. 
It turns out that there are certain other benefits in executing the first stage, especially when the users display human-like characteristics in their decision-making.

The revelation principle holds under fairly general settings provided that the participants’ preferences follow the predictions of expected utility theory. 
It is common to employ the concept of utility functions, central to economics theory, to capture the notion of preferences for the users. 
Expected utility theory extends these preferences to account for uncertainties, coming possibly from beliefs or other intrinsic sources of randomness present in the system.

It has been observed that human beings often do not behave according to expected utility theory. 
They often exhibit systematic deviations in their behavior and decision-making. 
Behavioral economics seeks to provide a better understanding of this phenomenon. 
Several books and articles have been written that cover the descriptive and prescriptive nature of human behavior.
It is especially important in the context of e-commerce applications, where people interact with the platform as part of their day-to-day lives. 
As a result, they tend to show more behavioral traits in such interactions.

From a theory point of view, cumulative prospect theory, a leading theory for decision-making under uncertainty (another Nobel prize winning work), proposed by Daniel Kahneman and Amos Tversky, is especially useful. It has a nice mathematical formulation and accounts for several behavioral aspects in a unified form. 
It tells you how each person evaluates different outcome scenarios under uncertainty.

Working on mechanism design with cumulative prospect theory instead of expected utility theory, one quickly realizes that the revelation principle does not hold anymore. 
This is a big deal. 
There are several reasons why we want something like the revelation principle to hold. 
One of the reasons as mentioned earlier was to simplify the search over all the possible communication protocols. 
Another reason is that the direct mechanisms are inherently nice from a strategic behavior point of view. 
In particular, the optimal strategy for each person is simple — report her type. This is important because many times the participants do not have a complete picture of the system at their disposal. 
Even if they have access to it, they do not possess the necessary computation power. 
This is typical of the e-commerce platforms that we are interested in. 
The participants come in all sizes varying in their computational power. 
The nice thing about direct mechanisms is that it is easy for the small participants to act optimally (although they might not understand completely why it is optimal), and the large participants even with all their extra abilities cannot do any better.

In our paper, we establish that by introducing a stage similar to the first stage above, we can recover a form of the revelation principle even under the behavioral setting of cumulative prospect theory. 
In this stage, the system oprator acts as a mediator and sends signals to all the participating agents.
These signals perform two main functions: it allows us to simplify the options shown to the users and it also allows us to align the participants beliefs. 
These properties come up naturally from our framework that we call the mediated mechanism design. (See this, for further details.)

The first property concerns the operability of the system. Since the interacting agents are human beings, we want to make the communication protocol in the first two stages as accessible as possible.
Just like driving a car is made accessible by giving as few controls to the driver as possible, but still maintaining a strong and complex engine, the first stage allows us to construct e-commerce applications similarly. Namely, we want a strong theory that will enable us to build a robust mechanism, and at the same time make it accessible without losing its integral parts.

The second property is closely related to the nudge theory (yet another incredible contribution to behavioral economics that won the Nobel prize). It is important to realize that the first stage has the power to influence the beliefs of the user and also her type. This is the aggressive part of the first stage.

Is it a bad thing? That depends on what is the purpose of the nudge. 
To make it clear, the sort of nudge we are interested in our paper is restricted to be truthful in nature.
Even then it is quite a powerful tool.
Although some might consider using misinformation, it often creates more problems than it intends to solve.
With a behavioral model at our disposal, we can better understand its influence and tell when something is harmful and not acceptable. 
It could suggest ways to improve the design of these mechanisms, both qualitatively and quantitatively. 
In my opinion, that is the purpose of any theory. 
Certainly, it will not be able to answer everything, but it is like the bridge example I mentioned above. 
Once we have a strong starting model to discuss and analyze the problem, we can start incorporating other more complex effects.

This brings us to the last stage, which takes the previous implementations of the mechanism and tries to improve it for the future. 
Most of the user interactions with the platform are of a repeated nature. 
This makes it possible to learn from previous interactions and improve the performance of the mechanism. 
These include several popular approaches from machine learning and reinforcement learning. 
Once we have decided the structure of our mechanism, like to sort of communications to employ, based on a better understanding of the underlying assumptions and objectives, we can then use data-driven techniques to optimize these designs.

Most of the technological developments that we see today are dominated by this third stage. 
The design of the first two stages is often taken for granted by assuming them to be something either observed, or seemingly intuitive, or based on trial and error. This approach is fast and often gets the job done. 
However, if we want to answer questions like the objectives and impacts of these mechanisms such as social impact, fairness, sustainability, environment-friendliness, and health-related concerns in a concrete manner, approaches based on well-defined theories stand a better chance of doing it.

Incorporating game theory in the design of e-commerce applications would allow us to give guarantees about the structure of our mechanism, systematically study its purpose and effects on society, and thus build better long-lasting systems.


    <a href="http://sohamphade.github.io/_site/gt_ecommerce//index.html">Continue reading</a>
    --->
  </article>
  </a>
</div>

<hr style="height:2px;border-width:0;color:gray;background-color:gray" />

<div class="bcolumn">
  <a href="http://sohamphade.github.io/_site/cptgames/index.html" style="text-decoration: none;">
  <article class="post">
  	<h2 class="post-title">Game Theory and Market Design when Agents have Cumulative Prospect Theory Preferences</h2>
    <time datetime="2020-11-09T00:00:00-08:00" class="post-date">09 Nov 2020</time>
    <h4> Cumulative prospect theory, which has enjoyed great empirical success, is an equally powerful tool when it comes to making theoretical advancements in behavioral game theory and mechanism design. </h4>
    <!--
    In this project, we systematically study game-theoretic settings (in particular, non-cooperative games) when the players’ preferences are modeled using cumulative prospect theory (CPT).
CPT is a generalization of expected utility theory (EUT) and one of the leading decision theories to model human preferences when faced with uncertainty. It was proposed by Daniel Kahneman and Amos Tversky for which Kahneman received the Nobel Memorial Prize in Economic Sciences. 
There has been a growing discussion concerning the benefits (and limits) of using CPT in game theory and economics. 
In fact, in the paper “Prospect theory in the wild: Evidence from the field”, Colin F. Camerer concludes:


  “there is no good scientific reason why it (prospect theory) should not replace expected utility in current research, and be given prominent space in economics textbooks.”


What better place to begin this endeavor than to study the notions of equilibrium that have been central to game theory and economic analysis!
In our paper titled “On the Geometry of Nash and Correlated Equilibria with CPT Preferences”, we take the notions of CPT Nash equilibrium and CPT correlated equilibrium defined by Kerim Keskin as our starting point and establish several geometric properties of these equilibrium notions. 
We explore questions such as the convexity and the connectivity properties of the correlated equilibria set, and the relation between the Nash equilibria and the correlated equilibria. 
For example, under EUT, it was known that the set of all correlated equilibria is a convex polytope. 
Keskin (2016) showed that this property need not hold under CPT. 
We prove that it can, in fact, be disconnected (if you are curious, check out the construction of an example in section 4 of the paper).
Nonetheless, certain properties like the Nash equilibria all lying on the boundary of the correlated equilibria set (proved by Nau et al. (2004)) continues to hold true,
although they require new proof techniques.

These new theoretical phenomena bring out some of the important distinctions resulting from CPT modeling.
They have practical implications for the design of experiments for learning the unknown game structures.
For example, in modern online advertising, the internal working of the ad-placement algorithms is typically unknown to the customers. 
Knowledge about the structure of the equilibria, especially under presumably more accurate behavioral models, would benefit the design of experiments and simulations.
They can also help in suggesting system improvements or policy changes such as advertising strategies, cybersecurity, or military tactics – like WOPR from WarGames!





Building on this, we consider the setting of learning in repeated games in the paper “Learning in Games with Cumulative Prospect Theoretic Players”. 
The literature on learning in games provides an alternative explanation to the equilibrium notions as a long-run outcome in repeated games with mild rationality assumptions on the players. 
They are especially important from a behavioral perspective where players have limited computational powers.
We consider the celebrated theorem of Rakesh Vohra and Dean Foster on the convergence of the empirical average of the action play to the set of correlated equilibria when players make calibrated forecasts and respond with myopically optimal actions.
One soon realizes that the notion of CPT correlated equilibrium, as defined by Keskin, is not enough to capture this result.
But instead, we need an appropriate convexification of this set that we call the mediated CPT correlated equilibrium.

In a correlated equilibrium, the mediator is assumed to recommend an action to each player to play.
We introduce the notion of mediated games in which the mediator is allowed to send signals from more general sets.
This is a specific type of game with communication as introduced by Myerson.
The mediated CPT correlated equilibria are then the Bayes-Nash equilibria of this mediated game.
Since the mediated CPT correlated equilibria are more general than the CPT correlated equilibria we get that the revelation principle in the context of correlated equilibria does not hold under CPT preferences.

Calibrated learning is one form of learning in games.
More generally, the result on the convergence to correlated equilibria is closely related to the notion of no-regret learning in games.
We prove that the set of CPT correlated equilibria is not approachable in the Blackwell approachability sense.
These results strongly suggest that the notion of mediated CPT correlated equilibrium is the appropriate notion to consider in this context.

A major revelation in the previous study is that: The Revelation Principle Fails under CPT!
A natural question is what happens in mechanism design where the revelation principle has played a fundamental role.
As suspected we observe that the revelation principle fails in mechanism design when agents have CPT preferences.
In the paper “Mechanism Design for CPT Agents: A General Framework and the Revelation Principle”, we develop an appropriate framework that we call mediated mechanism design that allows us to recover the revelation principle under certain settings.

The premise of a typical mechanism design scenario comprises a bunch of agents each having a private type consisting of their private information and preferences over the outcomes.
There is a system operator (or a principal) who controls the implementations in the system but cannot directly observe the private types of players.
To achieve optimal implementations conditioned on the types of the players, the system operator designs a communication protocol where the players can interact strategically in the resulting game.
This allows the system operator to elicit information about the private types of the players.
As an example, think of auctions.
The second-price sealed-bid auctions incentivize the players to reveal their private values truthfully, and the item is allocated to the player with the highest value at the second-highest bid.

For a modern application, consider ride-hailing services such as Uber or Lyft.
These apps present the customers with several options such as premium rides, shared rides, economy rides, etc.
The purpose of these options is to elicit the preferences of the customers and provide optimal services.
These systems have inherent uncertainties, and it is essential to account for the customers’ behavior towards such uncertainties.
The CPT-based analysis reveals that if we add a stage where each customer is sent a private message before she makes her option selection, then we can get improved results.
For example, these messages could take the form of selecting a customer at random to receive priority service or discounted pricing.
Such messages play the role of nudges that help in aligning the beliefs of the players for optimal service provisioning.

We already observe such nudges and incentives being used around us. 
But a theory explaining these practices is still in an infant stage.
Our mediated mechanism design framework is a very promising direction at explaining these observations theoretically and improving the design of these systems.
Mechanism design is commonly referred to as the engineering side of game theory. These theoretical and methodological results can have substantial implications for the design of behavior-aware systems such as online marketplaces and social networks.

There is an important common thread that runs through each of the above studies.
CPT preferences do not satisfy something called the betweenness property.
To understand this, let us consider a thought experiment.


  Suppose you are presented with two lotteries:

  
    
      You win $20,000 with a 34% chance and nothing with a 66% chance.
    
    
      You win $30,000 with a 17% chance and nothing with an 83% chance.

      Which lottery would you choose?

      Now consider the following third lottery:
    
    
      You win $30,000 with a 1% chance, $20,000 with a 32% chance, and nothing with a 67% chance.

      Would you prefer this lottery over the previous two lotteries?
    
  


Most people strictly prefer lottery 1 over lottery 2. But when asked about lottery 3, they choose it over the previous two lotteries. Now notice that lottery 3 can be thought of as a compound lottery of lottery 1 and lottery 2. Suppose you receive lottery 1 with a 16 in 17 chance and lottery 2 with a 1 in 17 chance. Then the compound lottery, if reduced to a single lottery, is exactly lottery 3.
Thus we observe that people might prefer to actively randomize over their options.
In the above setting, lottery 1 is a less risky gamble with a lower reward, and lottery 2 is a more risky gamble with a higher reward.
A risk-averse person would typically thus prefer lottery 1 over lottery 2.
However, when considering lottery 3, this person still perceives it to be low risk but is lured towards the 1% chance of winning a higher reward.
This explains the desire to go for lottery 3.

The nice thing about CPT preferences is that it neatly captures this effect through the probability weighting functions that overweight small percentages.
Building upon the idea that the players might prefer to actively randomize over their actions, we consider mixed strategies in non-cooperative games from a new perspective.
We refer to such actively mixed-strategies as black-box strategies.

Traditionally, mixed actions have been considered from two viewpoints, especially in the context of mixed-action Nash equilibrium. According to the first viewpoint, these are conscious randomizations by the players – each player only knows her mixed-action and not its pure realization. The notion of black-box strategies captures this interpretation of mixed-actions. According to the other viewpoint, players do not randomize, and each player chooses some definite action. 
But the other players need not know which one and the mixture represents their uncertainty, i.e., their conjecture about her choice.

Under CPT, these two interpretations get nicely untangled, and we get four different concepts of Nash equilibria depending on whether we allow randomization in each of the interpretations.
In the paper titled “Black-box Strategies and Equilibrium for CPT Players”, we develop these four notions and study their properties such as existence and relation to each other.

Cumulative Prospect Theory has several insights to offer. We must explore these theoretical ideas along with the experimental advances in behavioral game theory. 
We are at a fascinating juncture in this field, where theory and practice can assist each other in achieving something remarkable!

Further Reading


  
    Camerer, C. F. (1998). Prospect theory in the wild: Evidence from the field.
  
  
    Keskin K (2016) Equilibrium notions for agents with cumulative prospect theory preferences. Decision Analysis. 13(3):192-208.
  
  
    Phade, S. R., &amp; Anantharam, V. (2019). On the geometry of Nash and correlated equilibria with cumulative prospect theoretic preferences. Decision Analysis, 16(2), 142-156.
  
  
    Nau R, Canovas SG, Hansen P (2004) On the Geometry of Nash equilibria and correlated equilibria. Internat. J. Game Theory 32(4):443-453.
  
  
    Foster, D. P., &amp; Vohra, R. V. (1997). Calibrated learning and correlated equilibrium. Games and Economic Behavior, 21(1-2), 40.
  
  
    Hart, S., &amp; Mas‐Colell, A. (2000). A simple adaptive procedure leading to correlated equilibrium. Econometrica, 68(5), 1127-1150.
  
  
    Fudenberg, D., Drew, F., Levine, D. K., &amp; Levine, D. K. (1998). The theory of learning in games (Vol. 2). MIT press.
  
  
    Phade, S. R., &amp; Anantharam, V. (2018). Learning in Games with Cumulative Prospect Theoretic Preferences. arXiv preprint arXiv:1804.08005.
  
  
    Myerson, R. B. (2013). Game theory. Harvard university press.
  
  
    Aumann, R., &amp; Brandenburger, A. (1995). Epistemic conditions for Nash equilibrium. Econometrica: Journal of the Econometric Society, 1161-1180.
  
  
    Phade, S. R., &amp; Anantharam, V. (2020). Black-Box Strategies and Equilibrium for Games with Cumulative Prospect Theoretic Players. arXiv preprint arXiv:2004.09592.
  



    <a href="http://sohamphade.github.io/_site/cptgames//index.html">Continue reading</a>
    --->
  </article>
  </a>
</div>

<hr style="height:2px;border-width:0;color:gray;background-color:gray" />

<div class="bcolumn">
  <a href="http://sohamphade.github.io/_site/basd/index.html" style="text-decoration: none;">
  <article class="post">
  	<h2 class="post-title">Behavior-Aware System Design</h2>
    <time datetime="2020-11-05T00:00:00-08:00" class="post-date">05 Nov 2020</time>
    <h4> How can we design systems that are aware of human behavior and are guided by socially desirable principles and efficient resource allocation goals? </h4>
    <!--
    The recent decades have been marked by extensive technological advancements in domains such as Internet, Computing, Communication, and Artificial Intelligence.
These have lead to rapidly evolving technolgies such as cloud computing, automated services, communication platforms, big data software companies, and online marketplaces, that have become an integral part of our daily lives.

Our focus in the development of these technologies has essentially been at making them work efficiently.
For example, enormous engineering efforts have been directed towards the development of high speed communication tools, compact processing devices, large scale database deployments, and power efficient systems.

Only recently have we started paying closer attention to the way these systems interact with their users.
Although we are employing techniques such as geotargeting and personalized recommendations, a great deal remains yet to be undertood, especially, from the point of view of the correct guiding principles that would govern these human-computer interactions.
For example, I believe social welfare and efficient resource allocation should play a 
key role in the next stage of development of these technologies, 
and these principles should certainly dominate than other metrics such as revenue generation or customer engagement.

Several people have raised alarms towards the perils of social media with a huge ongoing debate regarding the correct usgae of these technologies, and the ethical responsibilities of the giant tech companines.
I am not going to discuss these issues in this blog post (although they are very closely related to the point I wish to make).
Instead, my goal is to take a modest scientific outlook towards the role of behavioral sciences in the design of such systems.

Let’s say you need to travel to keep an appointment or reach the airport to catch a flight. 
You open Google Maps or some other navigation app and check for possible routes and the estimated times of arrival. 
If you are short on time, then your topmost concern would be to reach your destination as soon as possible. 
Plus, you’d like to have a pretty good estimate of your arrival time.  Compare it with someone who might be using the same app but is looking for a scenic route and not so particular about his arrival time. 
At any given time, hundreds of thousands of users are using such apps to find what suits them the best. 
All these different people are going to have varied requirements based on their purposes and preferences while sharing the same infrastructure and resources. 
The app reccommendations are going to affect their choices, and their choices have externalities that affect the conditions for others. 
Ideally, we would like to make suggestions and assign routes to the different users based on everybody’s requirements and preferences in an “optimal” manner (with an appropriate definition of “optimality”).

For another example, consider a doctor who is performing a remote surgery and a social media influencer who is posting a video.
I would say that the doctor requires much more certainty in his bandwidth allocation as compared to the influencer. (I hope we agree on this!)
Can we design our systems to account for these differences in the user preferences and provide optimal services through appropriate incentives and nudges to the users?

This is actually not a new idea.
We have been doing this for several years.
Think about clearing the way for emergency vehicles or using emergency diversion routes.
We have been using such techniques to reallocate resources based on the needs. 
However, in the past, taking such policy steps required considerable efforts, and no wonder they were restricted to emergency situations. 
However, in today’s world, where almost everybody uses some sort of navigation app to decide their routes, we have many more ways to influence the routing of traffic. 
More so in the future with the advent of smart cars.

Sure, this requires knowing the preferences of the users. 
But economists have already given us an answer to this. 
It is not a far-fetched thought to imagine a world where you pay some points to get a route you prefer or earn some points to take a less preferred way. 
We already have this in the form of tolls for bridges and expressways. But I want you to imagine a mechanism that works on a much larger scale in an integrated manner. 
And one that accounts for the factors at the core of the problem - the users and their preferences.

This leads to two directions to focus on - designing an efficient mechanism that works on a large scale and capturing the preferences of the users as accurately as possible. 
For the first direction, implementing any policy at a large scale often requires mathematical models that capture the essence of the problem and building mechanisms and algorithms that would execute these policies. 
By and large, this has been the engineering approach towards solving these problems. 
Here the focus has been more on design efficiency and less on the social aspects along the lines of the second direction. 
In several engineering tasks, social goals such as welfare or the well-being of each individual were assumed to be straightforward and often taken for granted. 
On the other hand, these goals have mainly been the topic of interest in policy-making and economics. 
Only recently have people started to integrate ideas from both these fields.

I believe there is a good reason for it. 
Classical economics often treats people as if they were like Spock - formally called homo economicus - 
the rational individual who always accounts for all the available information and makes decisions involving great computational power. 
Firms and nations who have vast resources can afford to behave like Spock. And ideas from economics have played a significant role in governing their decisions. 
For example, the notion of utility allows us to convert several decision problems into an optimization problem and solve them (often encounterd under the name of cost-benefit analysis). 
However, for e-commerce platforms like social media and online marketplaces, where the participating agents are single individuals who perform several short-lived interactions with the platform, it is unusual that these agents would behave like Spock.

Working in an environment with growing human-computer interaction requires a better understanding of human behavior, often including the emotional traits displayed by them. 
On the one hand, these have created the necessity to account for the behavioral traits of the users,
and on the other hand, they have also provided us with extraordinary tools to act upon it.
Especially, the data boom.
This data comes in various forms right from the preferences of the users, their choices, their habits, their strengths, their weaknesses, to their emotional moods (which I recently learned can be measured by watch-like devices through the slight electrical changes in the skin).

These technological advancements have opened several new avenues at the intersection of engineering, technology, and social sciences.
It has raised significant interest in the past few decades, mostly under the label of behavioral economics. 
Although behavioral economics is often interpreted as creating nudges and changing the defaults to alter human behavior, I mean it in a more general sense.
I like to think of it as also comprising of techniques such as pricing and taxing commonly encountered in economics, but in a manner that is aware of the deviations in human behavior.
Or simply put, economics for information technologies without the Spock assumption.

You might have encountered such approaches under the label of boundedly rational behavior.
But I feel that this term implicitly imposes certain restrictions.
For example, a decision-maker is typically said to be rational if she her decisions are consistent with expected utility theory, and
any deviation from this behavior is due her lack of Spock like abilities, and hence marked as irrational.
On the contrary, I believe there are times when even if I had Spock like abilities I would chose to deviate from the prescriptions of expected utility theory. 
See for example the famous Allais paradox.
The point I wish to make here concerns with the general behavior which may or may not be a result of the lack of Spock like abilities.

For example, if we envision having automated decision-makers with Spock like abilities that assist each user, then we would like these assistants to make decisions according to the preferences of the corresponding users. 
Even if these preferences do not satisfy certain notions of rationality.
Certainly, we will have to make assumptions regarding the rationality features ranging from basic safety to commonly agreed upon aspects that one expects to be present in these systems.
But my point is that, along with the correction of non-Spock like behavior, the design of such systems should also be flexible enough in  their definition of rationality.

I believe, it is the integration of behavioral economics and engineering that holds the right recipe to design robust and scalable systems that would interact and assist the users in making decisions that are in their own and the society’s best interests. 
This is what I like to call Behavior-Aware System Design.
Its systematic study and implementation is the next big leap that we need.


    <a href="http://sohamphade.github.io/_site/basd//index.html">Continue reading</a>
    --->
  </article>
  </a>
</div>


      </main>

      <div class="navbar">
        
            <small><a class="" href="http://sohamphade.github.io/_site/index.html">About </a></small>
            
            <small><a class="" href="http://sohamphade.github.io/_site/research/index.html">Research </a></small>
            
            <small><a class="active" href="http://sohamphade.github.io/_site/archive/index.html">Blog </a></small>
            
            <small><a href="http://sohamphade.github.io/_site/assets/CV.pdf">CV </a></small>
            <small><a href="https://www.linkedin.com/in/soham-phade-a18ba634"> <i class="fa fa-linkedin-square"></i> </a></small>
            <small><a href="mailto:soham_phade@berkeley.edu"> <i class="fa fa-envelope"></i> </a></small>
            <small><a href="https://scholar.google.com/citations?user=6vH92bAAAAAJ&hl=en&oi=ao"> <i class="ai ai-google-scholar-square"></i> </a></small>
            <small><a href="https://dblp.org/pid/206/9094.html"> <i class="ai ai-dblp-square"></i> </a></small>
            <small><a href="https://www.researchgate.net/profile/Soham_Phade"> <i class="ai ai-researchgate-square"></i> </a></small>
      </div>


     <footer class="footer">
        <small>
          &copy;
          <time datetime="2021-10-22T11:15:48-07:00"
            >2021</time
          >. This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
        </small>
      </footer> 
    </div>



    
  </body>
</html>
